from dagster import asset, MaterializeResult, MetadataValue
import time
from dotenv import load_dotenv
from src.extract import fetch_anilist_page, save_page_to_db, get_db_connection
from src.config import MAX_PAGES_TO_FETCH

load_dotenv()

@asset(
    group_name="ingestion",
    description="Extrait les donnÃ©es d'AniList et les charge dans Postgres (raw_anilist_json)"
)
def raw_anilist_data(context) -> MaterializeResult:
    """
    Cet asset reprÃ©sente la table brute dans PostgreSQL.
    Sa fonction de 'matÃ©rialisation' est ton script d'extraction.
    """
    start_time = time.time()
    context.log.info("ðŸš€ DÃ©marrage de l'extraction AniList via Dagster...")
    
    conn = None
    try:
        conn = get_db_connection()
        current_page = 1
        has_next_page = True
        total_inserted = 0

        # Boucle d'extraction
        while has_next_page:
            if MAX_PAGES_TO_FETCH and current_page > MAX_PAGES_TO_FETCH:
                context.log.info(f"ðŸ›‘ Limite de {MAX_PAGES_TO_FETCH} pages atteinte pour ce run.")
                break

            context.log.info(f"ðŸ“„ Traitement de la page {current_page}...")
            
            # 1. Extract - on passe le logger Dagster
            api_response = fetch_anilist_page(current_page, logger=context.log)
            data = api_response['data']['Page']
            animes_list = data['media']
            page_info = data['pageInfo']

            # 2. Load - on passe le logger Dagster
            nb_inserted = save_page_to_db(conn, animes_list, logger=context.log)
            total_inserted += nb_inserted
            
            # 3. Prepare next loop
            has_next_page = page_info['hasNextPage']
            current_page += 1
            
            # Respectful delay
            time.sleep(2)  # Petit dÃ©lai pour ne pas spammer l'API

    except Exception as e:
        context.log.critical(f"ðŸ”¥ ArrÃªt inattendu du pipeline : {e}", exc_info=True)
        raise  # Important : on relance l'exception pour que Dagster marque l'asset comme failed
        
    finally:
        if conn:
            conn.close()
            context.log.debug("Connexion BDD fermÃ©e.")

    duration = time.time() - start_time
    context.log.info(f"ðŸŽ‰ Pipeline terminÃ© en {duration:.2f}s. Total animes traitÃ©s : {total_inserted}")

    # Retourner des mÃ©tadonnÃ©es riches pour le monitoring Dagster
    return MaterializeResult(
        metadata={
            "num_records": total_inserted,
            "last_page_fetched": current_page - 1,
            "duration_seconds": round(duration, 2),
            "pages_processed": current_page - 1,
            "avg_records_per_page": round(total_inserted / max(current_page - 1, 1), 2),
            "preview": MetadataValue.md(
                f"""
                ## Extraction AniList rÃ©ussie âœ…
                
                - **Total animes** : {total_inserted}
                - **Pages traitÃ©es** : {current_page - 1}
                - **DurÃ©e** : {duration:.2f}s
                - **Moyenne** : {total_inserted / max(current_page - 1, 1):.1f} animes/page
                """
            )
        }
    )